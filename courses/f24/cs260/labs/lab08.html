
<link href='../markdown.css' rel='stylesheet'></link>

<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}
  });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<!-- - - - - - - - - - - - - - - - - - - - - - - -->

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>lab08</title>
  <style>
    html {
      line-height: 1.7;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 40em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin-top: 1.7em;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.7em;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1.7em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1.7em 0 1.7em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      font-style: italic;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      background-color: #f0f0f0;
      font-size: 85%;
      margin: 0;
      padding: .2em .4em;
    }
    pre {
      line-height: 1.5em;
      padding: 1em;
      background-color: #f0f0f0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin-top: 1.7em;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
    }
    th, td {
      border-bottom: 1px solid lightgray;
      padding: 1em 3em 1em 0;
    }
    header {
      margin-bottom: 6em;
      text-align: center;
    }
    nav a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="cs260-lab-8-statistics-and-visualization">CS260 Lab 8: Statistics and Visualization</h1>
<h3><a href="https://classroom.github.com/a/PkGXyn_Y">GitHub Classroom Assignment Link</a></h3>
<hr />
<h2 id="overview-and-goals">Overview and goals</h2>
<p>The goals of this lab are:</p>
<ul>
<li>See how dimensionality reduction (specifically PCA) can be used for visualization</li>
<li>Practice making visualization choices as part of creating a plot</li>
<li>Understand the input/output of PCA, as well as the main algorithmic steps</li>
<li>Interpret the principal components in terms of evolutionary relationships</li>
<li>Understand how statistical tests can be used to answer questions about the data we observe</li>
<li>See how randomized trials and permutation testing can give us more precise results and avoid making assumptions</li>
</ul>
<p>
<hr />
<h2 id="part-1-pca-on-the-iris-flower-dataset">Part 1: PCA on the Iris Flower Dataset</h2>
<p>First we will apply PCA to a classic dataset of Iris flowers. This dataset is actually built-in to the package we will use: <code>sklearn</code>. If you do not already have this library, install it using <code>pip3</code>:</p>
<pre><code>pip3 install scikit-learn</code></pre>
<p>If this doesn’t work, it may be that you have multiple versions of Python 3. In that case run:</p>
<pre><code>python3 -m pip install scikit-learn</code></pre>
<p>Write your code in the file <code>pca.py</code>. Begin by importing the necessary packages:</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

from sklearn import decomposition
from sklearn import datasets</code></pre>
<p>The documentation for the PCA module can be found <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">here</a>.</p>
<p>The <code>datasets</code> module contains some example datasets, so we don’t have to download them. To load the Iris dataset, use:</p>
<pre><code>iris = datasets.load_iris()
X = iris.data
y = iris.target</code></pre>
<p><code>X</code> is our nxp matrix, where n=150 samples and p=4 features. Print <code>X</code>. The features in this case are not DNA data, but physical features of the flowers:</p>
<ol type="1">
<li>sepal length in cm</li>
<li>sepal width in cm</li>
<li>petal length in cm</li>
<li>petal width in cm</li>
</ol>
<p>Our goal here is to use PCA to visualize this data (since we cannot view the points in 4D!) Through the process of visualization, we’ll see if our data can be clustered based on the features above.</p>
<p>Now print <code>y</code>. These are the labels of each sample (subspecies of flower in this case). They are called:</p>
<ul>
<li>Iris Setosa (label 0)</li>
<li>Iris Versicolour (label 1)</li>
<li>Iris Virginica (label 2)</li>
</ul>
<p><code>y</code> is not used in PCA, it is only used afterward to visualize any clustering apparent in the results.</p>
<h3 id="run-pca">Run PCA</h3>
<p>Using the PCA documentation, create an instance of <code>PCA</code> with 2 components, then “fit” it using only <code>X</code>. Then use the transform method to transform the features (<code>X</code>) into 2D. (3 lines of code, but make sure you know what each line is doing!)</p>
<h3 id="plot-the-results">Plot the results</h3>
<p>Now we will use <code>matplotlib</code> to plot the results in 2D, as a scatter plot. The scatter function takes in a list of x-coordinates, a list of y-coordinates, and a list of colors for each point. Here the two axes are PC1 and PC2, and the points to plot are formed from the first and second <em>columns</em> of the transformed data.</p>
<pre><code>plt.scatter(x_coordinates, y_coordinates, c=colors) # example</code></pre>
<p>First plot without the colors to see what you get. Make sure to include axis labels and a title.</p>
<p>Then create a color dictionary that maps each <em>label</em> to a chosen color. Some colors have 1-letter abbreviations.</p>
<ul>
<li>‘b’ - blue</li>
<li>‘g’ - green</li>
<li>‘r’ - red</li>
<li>‘c’ - cyan</li>
<li>‘m’ - magenta</li>
<li>‘y’ - yellow</li>
<li>‘k’ - black</li>
<li>‘w’ - white</li>
</ul>
<p>There is also a longer list of named colors <a href="https://matplotlib.org/stable/gallery/color/named_colors.html">here</a>. After creating a color dictionary, use it to create a list of colors for all the points (thinking about what colors are easily distinguishable), then pass that in to your scatter method.</p>
<p>Legends are often created automatically in <code>matplotlib</code>, but for a scatter plot it’s a bit more difficult. We’ll actually create more plotting objects with no points, and then use these for our legend. Consider the code below. For each color, we’re creating a null-plot (the <code>'o'</code> means use circles for plotting). Then we’re mapping these null objects to names of the flowers (create a list of <code>names</code> for each class).</p>
<pre><code># create legend
leg_objects = []
for i in range(3):
    circle, = plt.plot([], &#39;o&#39;, c=color_dict[i])
    leg_objects.append(circle)
plt.legend(leg_objects,names)</code></pre>
<p>At the end, you should produce and save a plot called <code>figures/iris.pdf</code> (make sure to add/commit/push this figure).</p>
<pre><code>figures/iris.pdf</code></pre>
<p>The last step of this part is to create a PCA visualization for one other dataset that we have analyzed so far. I would recommend the <code>phoneme</code> dataset from Lab 7 (but remove the label when running PCA). Then color the points according to their label (similar to the iris dataset). For this part you can still work in the file <code>pca.py</code>. Try to avoid duplicated code, but it’s okay to have some since the plotting needs to be customized. Finally, save this plot as:</p>
<pre><code>figures/other_pca.pdf</code></pre>
<p>
<hr />
<p>
<hr />
<h2 id="part-2-coin-toss-example">Part 2: Coin Toss example</h2>
<p>First we will implement the scenario from Handout 17, where we toss a coin 80 times and observe 54 Heads. The question we’re trying to answer is: <em>Is this coin fair?</em></p>
<p>Implement this part of the lab in <code>coin_toss.py</code> (no command line arguments needed, but make sure to include a <code>main</code> function and other helper functions as appropriate). You will need the <code>scipy</code> library, which can be installed with <code>pip3</code>:</p>
<pre><code>pip3 install scipy</code></pre>
<p>If this doesn’t work, it may be that you have multiple versions of Python 3. In that case run:</p>
<pre><code>python3 -m pip install scipy</code></pre>
<h3 id="a-central-limit-theorem-clt-method">A) Central limit theorem (CLT) method</h3>
<p>First we will try to answer our question using the CLT. Following what we did in class, compute the test statistic (Z-score) for this example, under the null hypothesis of a fair coin. The CLT tells us that this Z-score is approximately drawn from a standard normal distribution: <code>N(0,1)</code>.</p>
<p>It is okay to hardcode <code>n = 80</code>, number of Heads = 54, etc. Please encode Tails as 0 and Heads as 1 for the purposes of the lab.</p>
<p>To compute the associated p-value, we will integrate the pdf (probability density function) of the standard normal distribution from the Z-score to positive infinity. To perform a two-sided test (i.e. that the coin is unfair in either direction, not just weighted toward Heads), we will then multiply the result by two.</p>
<p>To integrate (approximately) in Python, you can use the <code>quad</code> function:</p>
<pre><code>from scipy.integrate import quad

result, error = quad(func, a, b)</code></pre>
<p>In this example we would integrate the function <code>func</code> from <code>a</code> to <code>b</code> and obtain the area <code>result</code> with error <code>error</code>. See the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html">quad documentation</a> for more information.</p>
<p>Here we want to integrate the pdf of the standard normal distribution. This function is implemented for us as <code>norm.pdf</code>, after doing the following import:</p>
<pre><code>from scipy.stats import norm</code></pre>
<p>See the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html">norm documentation</a> for more information.</p>
<p>After obtaining the p-value, make sure to print it out like this:</p>
<pre><code>CLT p-value: &lt;p-value&gt;</code></pre>
<h3 id="b-randomized-trials-method">B) Randomized trials method</h3>
<p>The CLT method gives us an <em>approximation</em> of the p-value, based on the assumptions of the CLT (finite variance and “large enough” sample size). We can relax these assumptions by creating our own null distribution through randomized trials. If we flip a <em>fair</em> coin 80 times and record the number of Heads, then repeat this process many times, we will obtain an estimate of the null distribution. The steps below provide a rough guide for implementing this idea.</p>
<ul>
<li><p>First create a helper method that runs <em>one</em> trial. To make this slightly more general, it could take in the number of tosses <code>n</code>, and return the fraction of Heads observed. Make use of the Python <code>random</code> module.</p></li>
<li><p>Next run <em>many</em> trials and record the fraction of Heads each time.</p></li>
<li><p>Finally, count how many times you observe a result <em>as or more</em> extreme than 54 out of 80 Heads (make sure to account for the two-sided nature of our hypothesis). This number of extreme examples divided by the number of trials is our p-value. Print the p-value in a similar fashion:</p></li>
</ul>
<pre><code>Random trials p-value: &lt;p-value&gt;</code></pre>
<h3 id="plotting-the-distribution">Plotting the distribution</h3>
<p>The last step of Part 2 is to plot the null distribution and our observed data. Use <code>plt.hist</code> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html">documentation here</a> to plot a histogram of the fraction of Heads observed for all of your trials. I would recommend normalizing the histogram (so it “integrates” to 1) using <code>density=True</code>.</p>
<p>Then create a way of showing where our observed data (i.e. 54 Heads out of 80 tosses) lies on this distribution. Make sure to include axis labels and a title. Save your plot as:</p>
<pre><code>figures/coin_toss.pdf</code></pre>
<p>
<hr />
<h2 id="part-3-genome-size-example">Part 3: Genome Size example</h2>
<p>In the next part of the lab we will investigate a database of genomes from the <a href="https://en.wikipedia.org/wiki/Streptococcus_suis"><em>Streptococcus suis</em></a> bacteria, which is a zoonotic disease that can be transmitted from pigs to humans. The file <code>SSuis_Stats.xlsx</code> contains statistics about individual <em>S. suis</em> genomes from several populations. The question we will answer in Part 3 is: <em>Are the genome sizes of Population 1 and Population 2 significantly different?</em></p>
<p>Implement the next part of the lab in <code>genome_size.py</code> (no command line arguments needed). To read in this Excel file we will need a few external libraries, which can be installed with <code>pip3</code>:</p>
<pre><code>pip3 install pandas openpyxl xlrd</code></pre>
<p>or</p>
<pre><code>python3 -m pip install pandas openpyxl xlrd</code></pre>
<p>To read in the data, I recommend creating a helper function (that takes in a string <code>filename</code>) and returns two lists: one of the genome sizes of Population 1, and similarly for Population 2. First read the data into a <code>pandas</code> data frame:</p>
<pre><code>import pandas as pd

# inside helper function:
data_frame = pd.read_excel(filename, header=0) # header on line 0
print(data_frame)</code></pre>
<p>See the <a href="https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_excel.html">pandas excel documentation</a> for more information about reading Excel files into data frames.</p>
<p>We’re not going to discuss <code>pandas</code> in too much detail, but one of the nice things about this library is that we can obtain subsets of our data fairly easily.</p>
<p>Use the <a href="https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html">subset documentation</a> to devise a way to filter the rows so you only have those where “Population” is equal to 1. Similarly, filter the rows based on “Population” 2. After that, filter the columns so you only have “Total Genome Size” for each population. (Alternatively you could select this column first, then filter based on population). Finally, convert each set of numbers to a list and return both lists.</p>
<p>To double check your result, the first few genome sizes for each population are:</p>
<pre><code>pop1 = [2100834, 2098424, ... ]
pop2 = [2168777, 2324897, ... ]</code></pre>
<h3 id="a-central-limit-theorem-clt-method-1">A) Central limit theorem (CLT) method</h3>
<p>Similarly to Part 2, we will now use two different methods to obtain p-values. First we will investigate the CLT method. In this genome size example, we do not know the true mean and variance of the null distribution. It’s difficult to say exactly what the null distribution is! But our null <em>hypothesis</em> is that the genome sizes of samples from Population 1 and 2 are from the same (null) distribution.</p>
<p>Since we don’t know the mean and variance, we need to use a t-test. See the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html">t-test documentation</a> for more information, but the basic idea is:</p>
<pre><code>from scipy.stats import ttest_ind

result = ttest_ind(a, b)</code></pre>
<p>In this case we will assume equal variances and perform a two-sided test. <code>result</code> contains both a test statistic and a p-value. Make sure to print out your p-value like this:</p>
<pre><code>CLT p-value: &lt;p-value&gt;</code></pre>
<h3 id="b-permutation-testing-method">B) Permutation testing method</h3>
<p>In this example our randomized trial method will also be slightly different, since we don’t have access to the true null distribution. Instead, we will use <em>permutation testing</em>. This is a widely applicable concept, but in our case it will mean permuting the labels (i.e. Population 1 vs. 2) of the data, which will mimic the idea that the genome sizes were all drawn from the same distribution.</p>
<ul>
<li><p>First, implement a helper function that permutes the labels of the data. In practice, this function will take in two lists (one for each population) and return two lists with the data rearranged (so the first list still represents Population 1 and the second Population 2). It is up to you how to do this step, but think of your algorithm in advance, then start coding. Make sure that the <strong>size</strong> of the first returned list is the same as the size of the first input list (and similarly for the second).</p></li>
<li><p>Next, run <em>many</em> trials of permuting the labels. Each time, record the <em>difference</em> between the mean of those labeled Population 1 and those labeled Population 2. Since this will be a two-sided test, it might be easiest to record the absolute value of the difference.</p></li>
<li><p>Finally, count how many times you observe a result <em>as or more</em> extreme than the true difference in means of the original populations (make sure to account for the two-sided nature of our hypothesis). This number of extreme examples divided by the number of trials is our p-value. Print the p-value in a similar fashion:</p></li>
</ul>
<pre><code>Permutation testing p-value: &lt;p-value&gt;</code></pre>
<p>Note that your values may not be as similar as Part 2, but should still be quite close (same order of magnitude).</p>
<p>
<hr />
<h2 id="part-4-covid-cases-analysis-optional">Part 4: COVID cases analysis (OPTIONAL!)</h2>
<p>In this last part you can analyze the database of COVID cases from January 1, 2021, which is in the file <code>01-01-2021.csv</code>. This data is from the <a href="https://coronavirus.jhu.edu/about/how-to-use-our-data">Johns Hopkins COVID site</a>. This dataset shows various COVID statistics (number of cases, etc) broken down by region for one particular day. The idea is to ask a question about this dataset that can be answered with a procedure similar to Part 3.</p>
<p>One possible analysis would be to choose two states in the US, then gather a list of cases per <em>county</em> in each state. This will give you two lists, similar to Part 3. You could then frame a question like this: “On January 1, 2021, was COVID significantly worse in Pennsylvania or New York?” You could perform a similar analysis for other parts of the world, etc.</p>
<p>Include your implementation in <code>covid_cases.py</code> and write up your procedure/results in your <code>README.md</code>, following the questions below.</p>
<p>
<hr />
<h2 id="part-5-analysis">Part 5: Analysis</h2>
<p>Include the answers to the following questions in your <code>README.md</code>:</p>
<ol type="1">
<li><p>For the iris flower dataset in Part 1, what genealogical relationships can we infer from the PCA plot? For your other chosen dataset, what conclusions can you draw from the PCA plot? Does the number of visual clusters match the number of labels?</p></li>
<li><p>For Part 2, include both your p-values below. What is the probabilistic <em>interpretation</em> of the p-value in this coin toss situation? Given this interpretation, do you reject the null hypothesis (fair coin) or fail to reject?</p></li>
<li><p>For Part 3, include both your p-values below. Do you reject the null hypothesis (genomes from Population 1 and Population 2 are roughly the same size) or fail to reject?</p></li>
<!--<li><p>For Part 3, you may have noticed that your p-values were not as close as in Part 1. What assumption of the CLT might be violated with this dataset?</p></li>-->
<li><p>(Optional) If you did Part 4, write up your procedure and results here (what were you trying to test, how you went about it, what you found, etc).</p></li>
</ol>
<hr />
<h3 id="acknowledgements">Acknowledgements</h3>
<p><em>Materials by Sara Mathieson. Coin toss example based on MIT OpenCourseWare 18.650. Streptococcus suis dataset and genome size example from Eric Miller.</em></p>
</body>
</html>
